{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KH15KF1v_s6"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTTLoLtdgynQ",
        "outputId": "8687b210-5b81-46fe-9874-3f65b209fddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime-gpu==1.15.1 in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Collecting transformers===4.30.1\n",
            "  Obtaining dependency information for transformers===4.30.1 from https://files.pythonhosted.org/packages/b8/df/b01b5e67cde3883757c9212455cbb9169385dcab5858b7172199126b756d/transformers-4.30.1-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.30.1-py3-none-any.whl.metadata (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: optimum[onnxruntime-gpu]==1.9.1 in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: protobuf==3.20.1 in /usr/local/lib/python3.10/dist-packages (3.20.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: onnxoptimizer in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.18.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu==1.15.1) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (0.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (4.65.0)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]==1.9.1) (4.28.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]==1.9.1) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]==1.9.1) (1.15.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]==1.9.1) (0.9.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers) (4.6.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers===4.30.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers===4.30.1) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers===4.30.1) (3.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (65.7.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (16.0.6)\n",
            "INFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers[sentencepiece]>=4.26.0 (from optimum[onnxruntime-gpu]==1.9.1)\n",
            "  Obtaining dependency information for transformers[sentencepiece]>=4.26.0 from https://files.pythonhosted.org/packages/21/02/ae8e595f45b6c8edee07913892b3b41f5f5f273962ad98851dc6a564bbb9/transformers-4.31.0-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Obtaining dependency information for transformers[sentencepiece]>=4.26.0 from https://files.pythonhosted.org/packages/5b/0b/e45d26ccd28568013523e04f325432ea88a442b4e3020b757cf4361f0120/transformers-4.30.2-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers===4.30.1) (0.1.99)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu==1.15.1) (10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu==1.15.1) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->optimum[onnxruntime-gpu]==1.9.1) (0.15.2+cu118)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum[onnxruntime-gpu]==1.9.1) (2.1.3)\n",
            "Using cached transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.0\n",
            "    Uninstalling transformers-4.28.0:\n",
            "      Successfully uninstalled transformers-4.28.0\n",
            "Successfully installed transformers-4.30.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install onnxruntime-gpu==1.15.1 onnx transformers===4.30.1 optimum[onnxruntime-gpu]==1.9.1 protobuf==3.20.1 evaluate datasets onnxoptimizer optimum[exporters] diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0cas1M37-Ba",
        "outputId": "b02be561-877c-4b1a-8d30-a2fd25927f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 22 12:19:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFqCtlllwDZT"
      },
      "source": [
        "# Loading model\n",
        "\n",
        "As a starting point, we will need to select which model to use, in our case, we will be working with a pre-trained dataset, `naver-clova-ix/donut-base-finetuned-cord-v2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH_RHjMzKLVA"
      },
      "source": [
        "The next step is to convert our model to ONNX. To do this we can take advantage of the [optimum](https://huggingface.co/docs/optimum/) library from 🤗 Hugging Face, which helps us make our models more efficient in training and inference. In our case, we will take advantage of the implementations for ORT (ONNX Runtime).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn-EfWV6gjPv",
        "outputId": "d7ea961a-1c6f-436b-db4d-59f9ff8cc86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-22 12:19:05.944357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "The task `image-to-text` was manually specified, and past key values will not be reused in the decoding. if needed, please pass `--task image-to-text-with-past` to export using the past key values.\n",
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/feature_extraction_donut.py:28: FutureWarning: The class DonutFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DonutImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:229: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if num_channels != self.num_channels:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:219: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if width % self.patch_size[1] != 0:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:222: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if height % self.patch_size[0] != 0:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:533: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if min(input_resolution) <= self.window_size:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:625: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  was_padded = pad_values[3] > 0 or pad_values[5] > 0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:626: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if was_padded:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:265: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  should_pad = (height % 2 == 1) or (width % 2 == 1)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/donut/modeling_donut_swin.py:266: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if should_pad:\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py:910: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if input_shape[-1] > 1:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py:90: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  mask = torch.full((tgt_len, tgt_len), torch.tensor(torch.finfo(dtype).min, device=device), device=device)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py:236: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py:243: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/mbart/modeling_mbart.py:275: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Post-processing the exported models...\n",
            "Validating ONNX model models/onnx/encoder_model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (last_hidden_state)\n",
            "\t- Validating ONNX Model output \"last_hidden_state\":\n",
            "\t\t-[✓] (2, 1200, 1024) matches (2, 1200, 1024)\n",
            "\t\t-[x] values not close enough, max diff: 0.002078533172607422 (atol: 0.001)\n",
            "Validating ONNX model models/onnx/decoder_model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (present.2.encoder.key, present.3.decoder.key, present.1.decoder.value, present.0.encoder.key, logits, present.1.encoder.key, present.1.decoder.key, present.0.encoder.value, present.2.decoder.value, present.2.decoder.key, present.3.decoder.value, present.2.encoder.value, present.1.encoder.value, present.3.encoder.key, present.0.decoder.key, present.3.encoder.value, present.0.decoder.value)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 16, 57580) matches (2, 16, 57580)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.0.encoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.0.encoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.1.encoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.1.encoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.2.encoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.2.encoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.3.encoder.key\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "\t- Validating ONNX Model output \"present.3.encoder.value\":\n",
            "\t\t-[✓] (2, 16, 16, 64) matches (2, 16, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 0.001)\n",
            "The ONNX export succeeded with the warning: The maximum absolute difference between the output of the reference model and the ONNX exported model is not within the set tolerance 0.001:\n",
            "- last_hidden_state: max diff = 0.002078533172607422.\n",
            " The exported model was saved at: models/onnx\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "model_path = Path(\"./models/onnx\")\n",
        "!python3 -m optimum.exporters.onnx --model=naver-clova-ix/donut-base-finetuned-cord-v2 --task=vision2seq-lm  ./models/onnx --atol 1e-3 --opset=13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmYO5BNQv8jU"
      },
      "source": [
        "## Benchmark\n",
        "\n",
        "Now, we measure the size and throughput of the models obtained after optimization step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tU3u9DEsrID",
        "outputId": "4388c429-d20b-43ed-b2fe-c1e5eed2bfe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1012M\n",
            "-rw-r--r-- 1 root root   1M Jul 22 12:19 added_tokens.json\n",
            "-rw-r--r-- 1 root root   1M Jul 22 12:19 config.json\n",
            "-rw-r--r-- 1 root root 710M Jul 22 12:21 decoder_model.onnx\n",
            "-rw-r--r-- 1 root root 298M Jul 22 12:20 encoder_model.onnx\n",
            "-rw-r--r-- 1 root root   1M Jul 22 12:19 generation_config.json\n",
            "-rw-r--r-- 1 root root   1M Jul 22 12:19 preprocessor_config.json\n",
            "-rw-r--r-- 1 root root   2M Jul 22 12:19 sentencepiece.bpe.model\n",
            "-rw-r--r-- 1 root root   1M Jul 22 12:19 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root   1M Jul 22 12:19 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root   4M Jul 22 12:19 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "!ls -lh --block-size=M ./models/onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimize by Speedster"
      ],
      "metadata": {
        "id": "nv1x-SCHA3d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install protobuf==3.20.1 torch==1.13.1 nncf tensorrt==8.6.1\n",
        "!pip3 install onnx-graphsurgeon --extra-index-url https://pypi.ngc.nvidia.com\n",
        "!pip3 install speedster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjIrh8-QDP7N",
        "outputId": "23d02f02-47b2-4c39-9062-a16638279809"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf==3.20.1 in /usr/local/lib/python3.10/dist-packages (3.20.1)\n",
            "Collecting torch==1.13.1\n",
            "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "Requirement already satisfied: nncf in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: tensorrt==8.6.1 in /usr/local/lib/python3.10/dist-packages (8.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.7.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (65.7.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n",
            "Requirement already satisfied: ninja<1.11,>=1.10.0.post2 in /usr/local/lib/python3.10/dist-packages (from nncf) (1.10.2.4)\n",
            "Requirement already satisfied: texttable>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from nncf) (1.6.7)\n",
            "Requirement already satisfied: scipy<1.11,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from nncf) (1.10.1)\n",
            "Requirement already satisfied: networkx<=2.8.2,>=2.6 in /usr/local/lib/python3.10/dist-packages (from nncf) (2.8.2)\n",
            "Requirement already satisfied: numpy<1.24,>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from nncf) (1.23.5)\n",
            "Requirement already satisfied: pyparsing<3.0 in /usr/local/lib/python3.10/dist-packages (from nncf) (2.4.7)\n",
            "Requirement already satisfied: pymoo==0.5.0 in /usr/local/lib/python3.10/dist-packages (from nncf) (0.5.0)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from nncf) (4.3.3)\n",
            "Requirement already satisfied: pydot>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nncf) (1.4.2)\n",
            "Requirement already satisfied: jstyleson>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from nncf) (0.0.2)\n",
            "Requirement already satisfied: tqdm>=4.54.1 in /usr/local/lib/python3.10/dist-packages (from nncf) (4.65.0)\n",
            "Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from nncf) (8.3.1)\n",
            "Requirement already satisfied: pandas<2.1,>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nncf) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from nncf) (1.2.2)\n",
            "Requirement already satisfied: openvino-telemetry in /usr/local/lib/python3.10/dist-packages (from nncf) (2023.1.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from pymoo==0.5.0->nncf) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.10/dist-packages (from pymoo==0.5.0->nncf) (1.6.2)\n",
            "Requirement already satisfied: cma==2.7 in /usr/local/lib/python3.10/dist-packages (from pymoo==0.5.0->nncf) (2.7.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->nncf) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->nncf) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1,>=1.1.5->nncf) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1,>=1.1.5->nncf) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->nncf) (3.2.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.3->pymoo==0.5.0->nncf) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.5.0->nncf) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.5.0->nncf) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.5.0->nncf) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.5.0->nncf) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.5.0->nncf) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->pymoo==0.5.0->nncf) (8.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.1,>=1.1.5->nncf) (1.16.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch-tensorrt 1.4.0 requires torch<2.1,>=2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: onnx-graphsurgeon in /usr/local/lib/python3.10/dist-packages (0.3.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx-graphsurgeon) (1.23.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx-graphsurgeon) (1.12.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-graphsurgeon) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-graphsurgeon) (4.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: speedster in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: nebullvm>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from speedster) (0.10.0)\n",
            "Requirement already satisfied: tabulate>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from speedster) (0.9.0)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (1.23.5)\n",
            "Requirement already satisfied: py-cpuinfo>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (6.0.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.36.0 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (4.65.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (23.1)\n",
            "Requirement already satisfied: loguru>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from nebullvm>=0.9.0->speedster) (0.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->nebullvm>=0.9.0->speedster) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->nebullvm>=0.9.0->speedster) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->nebullvm>=0.9.0->speedster) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->nebullvm>=0.9.0->speedster) (3.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m nebullvm.installers.auto_installer --frameworks all --extra-backends all --compilers all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sCZGU1QVUzk",
        "outputId": "4e7be2f3-e0df-4eb0-bbd2-6821af51c916"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-22 12:22:14.575782: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-22 12:22:15.554323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-07-22 12:22:17.285714: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-22 12:22:17.292958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-22 12:22:17.293186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[32m2023-07-22 12:22:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mRunning auto install of nebullvm dependencies\u001b[0m\n",
            "Collecting transformers<=4.28.0\n",
            "  Using cached transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers<=4.28.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers<=4.28.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.28.0) (3.4)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.30.1\n",
            "    Uninstalling transformers-4.30.1:\n",
            "      Successfully uninstalled transformers-4.30.1\n",
            "Successfully installed transformers-4.28.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: cuda-python in /usr/local/lib/python3.10/dist-packages (12.2.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python) (0.29.36)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: onnx<=1.14.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx<=1.14.0,>=1.10.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from onnx<=1.14.0,>=1.10.0) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx<=1.14.0,>=1.10.0) (4.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: onnx_graphsurgeon in /usr/local/lib/python3.10/dist-packages (0.3.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon) (1.23.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon) (1.12.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx_graphsurgeon) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx_graphsurgeon) (4.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.11.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (1.11.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: onnxmltools>=1.11.0 in /usr/local/lib/python3.10/dist-packages (1.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxmltools>=1.11.0) (1.23.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxmltools>=1.11.0) (1.12.0)\n",
            "Requirement already satisfied: skl2onnx in /usr/local/lib/python3.10/dist-packages (from onnxmltools>=1.11.0) (1.14.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxmltools>=1.11.0) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxmltools>=1.11.0) (4.7.1)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=0.19 in /usr/local/lib/python3.10/dist-packages (from skl2onnx->onnxmltools>=1.11.0) (1.2.2)\n",
            "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from skl2onnx->onnxmltools>=1.11.0) (1.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common>=1.7.0->skl2onnx->onnxmltools>=1.11.0) (23.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=0.19->skl2onnx->onnxmltools>=1.11.0) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=0.19->skl2onnx->onnxmltools>=1.11.0) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=0.19->skl2onnx->onnxmltools>=1.11.0) (3.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: onnxsim in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxsim) (1.12.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim) (13.4.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim) (1.23.5)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim) (3.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim) (4.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[32m2023-07-22 12:23:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrying to install openvino on the platform...\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mopenvino installed successfully!\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrying to install tensor_rt on the platform...\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mtensor_rt installed successfully!\u001b[0m\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Installing collected packages: protobuf\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "deepsparse 1.5.2 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "onnx 1.12.0 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "sparsezoo 1.5.2 requires numpy<=1.21.6,>=1.0.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tf2onnx>=1.8.4 in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx>=1.8.4) (1.23.5)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx>=1.8.4) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx>=1.8.4) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx>=1.8.4) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx>=1.8.4) (2.0.7)\n",
            "Collecting protobuf<=3.20.1,>=3.12.2 (from onnx>=1.4.1->tf2onnx>=1.8.4)\n",
            "  Using cached protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.4.1->tf2onnx>=1.8.4) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx>=1.8.4) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx>=1.8.4) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx>=1.8.4) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx>=1.8.4) (3.4)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery 3.10.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.13.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.11.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.59.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.12.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "sparsezoo 1.5.2 requires numpy<=1.21.6,>=1.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[32m2023-07-22 12:23:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrying to install deepsparse on the platform...\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mdeepsparse installed successfully!\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrying to install intel_neural_compressor on the platform...\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mintel_neural_compressor installed successfully!\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrying to install tensor_rt on the platform...\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mtensor_rt installed successfully!\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrying to install torch_tensor_rt on the platform...\u001b[0m\n",
            "Looking in links: https://github.com/pytorch/TensorRT/releases/expanded_assets/v1.3.0\n",
            "Requirement already satisfied: torch-tensorrt in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Collecting torch<2.1,>=2.0.1 (from torch-tensorrt)\n",
            "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0.1->torch-tensorrt) (65.7.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0.1->torch-tensorrt) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch-tensorrt) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch-tensorrt) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0.1->torch-tensorrt) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0.1->torch-tensorrt) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1\n",
            "    Uninstalling torch-1.13.1:\n",
            "      Successfully uninstalled torch-1.13.1\n",
            "Successfully installed torch-2.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorrt<=8.6.1,>=8.6.0 in /usr/local/lib/python3.10/dist-packages (8.6.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[32m2023-07-22 12:23:54\u001b[0m | \u001b[38;2;211;211;211mWARNING \u001b[0m | \u001b[38;2;211;211;211mUnable to install torch_tensor_rt on this platform. The compiler will be skipped. \u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrying to install faster_transformer on the platform...\u001b[0m\n",
            "\u001b[32m2023-07-22 12:23:54\u001b[0m | \u001b[38;2;211;211;211mWARNING \u001b[0m | \u001b[38;2;211;211;211mUnable to install faster_transformer on this platform. The compiler will be skipped. \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import re\n",
        "import transformers\n",
        "from PIL import Image\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "model_base_id = \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n",
        "device = \"cuda\"\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(model_base_id)\n",
        "model = VisionEncoderDecoderModel.from_pretrained(model_base_id)\n",
        "\n",
        "# Move model to GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQOn4h4R7VDu",
        "outputId": "1201de1f-e494-4c99-d2bb-2e98ef0769f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionEncoderDecoderModel(\n",
              "  (encoder): DonutSwinModel(\n",
              "    (embeddings): DonutSwinEmbeddings(\n",
              "      (patch_embeddings): DonutSwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): DonutSwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-13): 14 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): DonutSwinPatchMerging(\n",
              "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): DonutSwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x DonutSwinLayer(\n",
              "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): DonutSwinAttention(\n",
              "                (self): DonutSwinSelfAttention(\n",
              "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): DonutSwinSelfOutput(\n",
              "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): DonutSwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): DonutSwinIntermediate(\n",
              "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): DonutSwinOutput(\n",
              "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (decoder): MBartForCausalLM(\n",
              "    (model): MBartDecoderWrapper(\n",
              "      (decoder): MBartDecoder(\n",
              "        (embed_tokens): Embedding(57580, 1024, padding_idx=1)\n",
              "        (embed_positions): MBartLearnedPositionalEmbedding(770, 1024)\n",
              "        (layers): ModuleList(\n",
              "          (0-3): 4 x MBartDecoderLayer(\n",
              "            (self_attn): MBartAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (activation_fn): GELUActivation()\n",
              "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (encoder_attn): MBartAttention(\n",
              "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (lm_head): Linear(in_features=1024, out_features=57580, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import onnxoptimizer\n",
        "import onnxruntime\n",
        "import torch\n",
        "from PIL import Image\n",
        "import onnx\n",
        "\n",
        "\n",
        "import onnxruntime as onnxrt\n",
        "import requests\n",
        "from transformers import AutoConfig, AutoModelForVision2Seq, DonutProcessor, VisionEncoderDecoderModel\n",
        "from transformers.generation.utils import GenerationMixin\n",
        "from transformers.modeling_outputs import BaseModelOutput, Seq2SeqLMOutput\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "device_desc = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_desc)\n",
        "\n",
        "class ORTEncoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main_input_name = \"pixel_values\"\n",
        "        self._device = device\n",
        "        self.session = onnxrt.InferenceSession(\n",
        "            \"./models/onnx/encoder_model.onnx\", providers=[\"CUDAExecutionProvider\",\"CPUExecutionProvider\"]\n",
        "        )\n",
        "        self.input_names = {input_key.name: idx for idx, input_key in enumerate(self.session.get_inputs())}\n",
        "        self.output_names = {output_key.name: idx for idx, output_key in enumerate(self.session.get_outputs())}\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        pixel_values: torch.FloatTensor,\n",
        "        **kwargs,\n",
        "    ) -> BaseModelOutput:\n",
        "\n",
        "        onnx_inputs = {\"pixel_values\": pixel_values.cpu().detach().numpy()}\n",
        "\n",
        "        # Run inference\n",
        "        outputs = self.session.run(None, onnx_inputs)\n",
        "        last_hidden_state = torch.from_numpy(outputs[self.output_names[\"last_hidden_state\"]]).to(self._device)\n",
        "\n",
        "        return BaseModelOutput(last_hidden_state=last_hidden_state)\n",
        "\n",
        "\n",
        "class ORTDecoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main_input_name = \"pixel_values\"\n",
        "        self._device = device\n",
        "        self.session = onnxrt.InferenceSession(\n",
        "          \"./models/onnx/decoder_model.onnx\", providers=[\"CUDAExecutionProvider\",\"CPUExecutionProvider\"]\n",
        "        )\n",
        "        self.input_names = {input_key.name: idx for idx, input_key in enumerate(self.session.get_inputs())}\n",
        "        self.output_names = {output_key.name: idx for idx, output_key in enumerate(self.session.get_outputs())}\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        attention_mask: torch.LongTensor,\n",
        "        encoder_hidden_states: torch.FloatTensor,\n",
        "    ) -> Seq2SeqLMOutput:\n",
        "\n",
        "        onnx_inputs = {\n",
        "            \"input_ids\": input_ids.cpu().detach().numpy(),\n",
        "        }\n",
        "\n",
        "        if \"attention_mask\" in self.input_names:\n",
        "            onnx_inputs[\"attention_mask\"] = attention_mask.cpu().detach().numpy()\n",
        "\n",
        "        # Add the encoder_hidden_states inputs when needed\n",
        "        if \"encoder_hidden_states\" in self.input_names:\n",
        "            onnx_inputs[\"encoder_hidden_states\"] = encoder_hidden_states.cpu().detach().numpy()\n",
        "\n",
        "        # Run inference\n",
        "        outputs = self.session.run(None, onnx_inputs)\n",
        "\n",
        "        logits = torch.from_numpy(outputs[self.output_names[\"logits\"]]).to(self._device)\n",
        "        return Seq2SeqLMOutput(logits=logits)\n",
        "\n",
        "    def prepare_inputs_for_generation(self, input_ids, attention_mask=None, encoder_hidden_states=None, **kwargs):\n",
        "        if attention_mask is None:\n",
        "            attention_mask = input_ids.new_ones(input_ids.shape)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"encoder_hidden_states\": encoder_hidden_states,\n",
        "        }\n",
        "\n",
        "\n",
        "class ORTModelForVision2Seq(VisionEncoderDecoderModel, GenerationMixin):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        config = AutoConfig.from_pretrained(model_base_id)\n",
        "        super().__init__(config)\n",
        "        self._device = device\n",
        "\n",
        "        self.encoder = ORTEncoder()\n",
        "        self.decoder = ORTDecoder()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        pixel_values: Optional[torch.FloatTensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        encoder_outputs: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
        "        **kwargs,\n",
        "    ) -> Seq2SeqLMOutput:\n",
        "        if encoder_outputs is None:\n",
        "            encoder_outputs = self.encoder(pixel_values=pixel_values.to(device))\n",
        "\n",
        "        # Decode\n",
        "        decoder_attention_mask = decoder_input_ids.new_ones(decoder_input_ids.shape)\n",
        "        decoder_outputs = self.decoder(\n",
        "            input_ids=decoder_input_ids,\n",
        "            attention_mask=decoder_attention_mask,\n",
        "            encoder_hidden_states=encoder_outputs.last_hidden_state,\n",
        "        )\n",
        "\n",
        "        return Seq2SeqLMOutput(\n",
        "            logits=decoder_outputs.logits,\n",
        "        )\n",
        "\n",
        "    def prepare_inputs_for_generation(self, input_ids, attention_mask=None, encoder_outputs=None, **kwargs):\n",
        "\n",
        "        return {\n",
        "            \"decoder_input_ids\": input_ids,\n",
        "            \"decoder_atttention_mask\": input_ids,\n",
        "            \"encoder_outputs\": encoder_outputs,\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def device(self) -> torch.device:\n",
        "        return self._device\n",
        "\n",
        "    @device.setter\n",
        "    def device(self, value: torch.device):\n",
        "        self._device = value\n",
        "\n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return self"
      ],
      "metadata": {
        "id": "PiP_XUztQBz3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_crop(im, device):\n",
        "  im = Image.open(r\"receipt.jpg\")\n",
        "  im = im.convert(\"RGB\")\n",
        "  newsize = (300, 400)\n",
        "  im = im.resize(newsize)\n",
        "  pixel_values = processor(im, return_tensors=\"pt\").pixel_values\n",
        "  pixel_values=pixel_values.to(device)\n",
        "  return pixel_values"
      ],
      "metadata": {
        "id": "rdkX39qGGx1j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from speedster import optimize_model\n",
        "from speedster import save_model\n",
        "from torch.utils.data import DataLoader\n",
        "import onnxruntime as onnxrt\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Images\n",
        "imgs = ['https://media.snopes.com/2017/07/walmart-jajket.jpg']  # batch of images\n",
        "image = \"receipt.jpg\"\n",
        "Image.open(requests.get(imgs[0], stream=True).raw).save(image)\n",
        "\n",
        "# input data from image\n",
        "encoded_inputs = [((read_and_crop(image,device),), None) for _ in range(2)]\n",
        "\n",
        "onnx_model = ORTModelForVision2Seq()\n",
        "onnx_model = onnx_model.to(device)\n",
        "\n",
        "# Testing ONNX Inference - START\n",
        "model.config.decoder_start_token_id = 2\n",
        "onnx_model.config.vocab_size = onnx_model.config.decoder.vocab_size\n",
        "onnx_model.config.pad_token_id = onnx_model.config.decoder.pad_token_id = processor.tokenizer.pad_token_id\n",
        "onnx_model.config.eos_token_id = onnx_model.config.decoder.eos_token_id = processor.tokenizer.sep_token_id\n",
        "\n",
        "start = timer()\n",
        "\n",
        "sequence = model.generate(read_and_crop(image,device).to(device),early_stopping=True,\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    eos_token_id=processor.tokenizer.eos_token_id,\n",
        "    use_cache=False,\n",
        "    num_beams=1,\n",
        "    bad_words_ids=[[processor.tokenizer.unk_token_id]])\n",
        "\n",
        "sequence = processor.batch_decode(sequence, skip_special_tokens=False, device=device)[0]\n",
        "sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
        "sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n",
        "print(\"Generated JSON Output : \",processor.token2json(sequence))\n",
        "\n",
        "end = timer()\n",
        "print('elapsed time: ', end - start) # Time in seconds, e.g. 5.38091952400282\n",
        "# Testing ONNX Inference - END\n",
        "\n",
        "\n",
        "# Run Speedster optimization\n",
        "optimized_model = optimize_model(\n",
        "    model=onnx_model,\n",
        "    input_data=encoded_inputs,\n",
        "    optimization_time=\"unconstrained\",\n",
        "    device=\"gpu:0\",\n",
        "    metric_drop_ths=0.8\n",
        ")\n",
        "\n",
        "save_model(optimized_model, \"./models/speedster\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "eeVIagJoA8Sr",
        "outputId": "8840958b-2aba-425e-969f-1c28039669a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Post-training Optimization Tool is deprecated and will be removed in the future. Please use Neural Network Compression Framework instead: https://github.com/openvinotoolkit/nncf\n",
            "Nevergrad package could not be imported. If you are planning to use any hyperparameter optimization algo, consider installing it using pip. This implies advanced usage of the tool. Note that nevergrad is compatible only with Python 3.7+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated JSON Output :  {'text_sequence': \"Walaut's Save money. Live better. suvericy's Md Md M\"}\n",
            "elapsed time:  2.223904781000101\n",
            "\u001b[32m2023-07-22 12:24:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mRunning Speedster on GPU:0\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d4b727914a23>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Run Speedster optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m optimized_model = optimize_model(\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speedster/api/functions.py\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(model, input_data, metric_drop_ths, metric, optimization_time, dynamic_info, config_file, ignore_compilers, ignore_compressors, store_latencies, device, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mLoggingContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         return root_op.to(device).execute(\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speedster/root_op.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, model, input_data, metric_drop_ths, metric, optimization_time, dynamic_info, config_file, ignore_compilers, ignore_compressors, store_latencies, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         result = self.optimize_inference_op.to(self.device).execute(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nebullvm/operations/optimizations/optimize_inference.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, model, input_data, metric_drop_ths, metric, optimization_time, dynamic_info, config_file, ignore_compilers, ignore_compressors, store_latencies, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQUANTIZATION_METRIC_MAP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         model_params: ModelParams = extract_info_from_data(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nebullvm/tools/utils.py\u001b[0m in \u001b[0;36mextract_info_from_data\u001b[0;34m(model, input_data, dl_framework, dynamic_info, device, is_diffusion)\u001b[0m\n\u001b[1;32m    227\u001b[0m ):\n\u001b[1;32m    228\u001b[0m     \u001b[0mcheck_dynamic_info_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     batch_size, input_sizes, input_types, dynamic_info = INFO_EXTRACTION_DICT[\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mdl_framework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nebullvm/tools/pytorch.py\u001b[0m in \u001b[0;36mextract_info_from_torch_data\u001b[0;34m(model, dataloader, dynamic_axis, device, is_diffusion)\u001b[0m\n\u001b[1;32m    180\u001b[0m     dynamic_axis = ifnone(\n\u001b[1;32m    181\u001b[0m         \u001b[0mdynamic_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0m_extract_dynamic_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nebullvm/tools/pytorch.py\u001b[0m in \u001b[0;36m_extract_dynamic_axis\u001b[0;34m(torch_model, dataloader, input_sizes, device, max_data)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         )\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_torch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mdynamic_axis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nebullvm/tools/pytorch.py\u001b[0m in \u001b[0;36mrun_torch_model\u001b[0;34m(torch_model, input_tensors, device, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m             )\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-0891e9a05b6d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, decoder_input_ids, encoder_outputs, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mdecoder_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         decoder_outputs = self.decoder(\n\u001b[1;32m    116\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'new_ones'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}